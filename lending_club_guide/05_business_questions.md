# üéØ Business Questions ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏∏‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó

## üìã ‡∏™‡∏≤‡∏£‡∏ö‡∏±‡∏ç
- [üìä Descriptive Analytics](#-descriptive-analytics)
- [üìà Diagnostic Analytics](#-diagnostic-analytics)
- [üîÆ Predictive Analytics](#-predictive-analytics)
- [üéØ Prescriptive Analytics](#-prescriptive-analytics)
- [üìä Data Visualization Questions](#-data-visualization-questions)
- [ü§ñ Machine Learning Applications](#-machine-learning-applications)
- [üíº Business Intelligence & KPIs](#-business-intelligence--kpis)

---

## üìä Descriptive Analytics
*"What happened?" - ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡∏∂‡πâ‡∏ô‡πÉ‡∏ô‡∏≠‡∏î‡∏µ‡∏ï*

### üéØ **Portfolio Overview Questions**

#### **1. ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à (Business Overview)**
```python
# Q1: ‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏¥‡∏ö‡πÇ‡∏ï‡∏Ç‡∏≠‡∏á‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à‡∏ï‡∏≤‡∏°‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤
import pandas as pd
import numpy as np

# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ß‡∏•‡∏≤
df['issue_d'] = pd.to_datetime(df['issue_d'])
df['issue_year'] = df['issue_d'].dt.year
df['issue_month'] = df['issue_d'].dt.month

monthly_growth = df.groupby([df['issue_d'].dt.to_period('M')]).agg({
    'loan_amnt': ['count', 'sum', 'mean'],
    'int_rate': 'mean'
}).round(2)

print("Monthly Business Growth:")
print(monthly_growth.head(10))
```

**Business Impact**: ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à trend ‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏¥‡∏ö‡πÇ‡∏ï, seasonal patterns, ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡∏≠‡∏á‡∏û‡∏§‡∏ï‡∏¥‡∏Å‡∏£‡∏£‡∏°‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤

#### **2. ‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏ï‡∏≤‡∏°‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á**
```python
# Q2: ‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏™‡∏¥‡∏ô‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏ï‡∏≤‡∏°‡πÄ‡∏Å‡∏£‡∏î
grade_distribution = df.groupby('grade').agg({
    'loan_amnt': ['count', 'sum', 'mean'],
    'int_rate': 'mean',
    'is_bad_loan': 'mean'
}).round(2)

print("‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏™‡∏¥‡∏ô‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏ï‡∏≤‡∏°‡πÄ‡∏Å‡∏£‡∏î:")
print(grade_distribution)
```

**Business Questions**:
- ‡πÄ‡∏Å‡∏£‡∏î‡πÑ‡∏´‡∏ô‡∏°‡∏µ‡∏õ‡∏£‡∏¥‡∏°‡∏≤‡∏ì‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î?
- ‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏î‡∏≠‡∏Å‡πÄ‡∏ö‡∏µ‡πâ‡∏¢‡∏™‡∏∞‡∏ó‡πâ‡∏≠‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡πÑ‡∏î‡πâ‡∏î‡∏µ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà?
- ‡πÄ‡∏Å‡∏£‡∏î‡πÑ‡∏´‡∏ô‡∏Ñ‡∏ß‡∏£‡∏Ç‡∏¢‡∏≤‡∏¢‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à/‡∏•‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á?

### üí∞ **Financial Performance**

#### **3. ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ú‡∏•‡∏ï‡∏≠‡∏ö‡πÅ‡∏ó‡∏ô**
```python
# Q3: ROI Analysis
completed_loans = df[df['loan_status'].isin(['Fully Paid', 'Charged Off'])].copy()
completed_loans['total_return'] = completed_loans['total_pymnt'] + completed_loans['recoveries']
completed_loans['net_return'] = completed_loans['total_return'] - completed_loans['funded_amnt']
completed_loans['roi_pct'] = (completed_loans['net_return'] / completed_loans['funded_amnt']) * 100

# ROI by grade
roi_by_grade = completed_loans.groupby('grade')['roi_pct'].agg(['mean', 'median', 'std'])
print("ROI by Grade:")
print(roi_by_grade)
```

---

## üìà Diagnostic Analytics
*"Why did it happen?" - ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏™‡∏≤‡πÄ‡∏´‡∏ï‡∏∏‡∏Ç‡∏≠‡∏á‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡∏∂‡πâ‡∏ô*

### üîç **Risk Factor Analysis**

#### **4. ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á**
```python
# Q4: ‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡∏ú‡∏•‡∏ï‡πà‡∏≠‡∏Å‡∏≤‡∏£‡∏ú‡∏¥‡∏î‡∏ô‡∏±‡∏î‡∏ä‡∏≥‡∏£‡∏∞
import scipy.stats as stats

# Chi-square test for categorical variables
categorical_vars = ['grade', 'home_ownership', 'purpose', 'verification_status']
risk_analysis = {}

for var in categorical_vars:
    contingency_table = pd.crosstab(df[var], df['is_bad_loan'])
    chi2, p_value, dof, expected = stats.chi2_contingency(contingency_table)
    risk_analysis[var] = {
        'chi2': chi2,
        'p_value': p_value,
        'significant': p_value < 0.05
    }

for var, stats_data in risk_analysis.items():
    print(f"{var}: Chi-square = {stats_data['chi2']:.2f}, p-value = {stats_data['p_value']:.4f}")
```

#### **5. Cohort Analysis**
```python
# Q5: ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå performance ‡∏ï‡∏≤‡∏° cohort (‡∏õ‡∏µ‡∏ó‡∏µ‡πà‡∏≠‡∏≠‡∏Å‡∏™‡∏¥‡∏ô‡πÄ‡∏ä‡∏∑‡πà‡∏≠)
cohort_performance = df.groupby('issue_year').agg({
    'is_bad_loan': 'mean',
    'loan_amnt': ['count', 'sum'],
    'int_rate': 'mean'
}).round(3)

print("Cohort Performance by Year:")
print(cohort_performance)
```

---

## üîÆ Predictive Analytics
*"What will happen?" - ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏‡∏Å‡∏≤‡∏£‡∏ì‡πå‡πÉ‡∏ô‡∏≠‡∏ô‡∏≤‡∏Ñ‡∏ï*

### ü§ñ **Credit Risk Modeling**

#### **6. Default Prediction Model**
```python
# Q6: ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ú‡∏¥‡∏î‡∏ô‡∏±‡∏î‡∏ä‡∏≥‡∏£‡∏∞
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, roc_auc_score
from sklearn.preprocessing import LabelEncoder

# Feature selection
features = [
    'loan_amnt', 'int_rate', 'installment', 'annual_inc', 'dti',
    'fico_range_low', 'fico_range_high', 'revol_util', 'delinq_2yrs', 
    'inq_last_6mths', 'open_acc', 'pub_rec'
]

# Prepare data
X = df[features].fillna(df[features].median())
y = df['is_bad_loan']

# Remove any remaining NaN values
mask = ~(X.isnull().any(axis=1) | y.isnull())
X = X[mask]
y = y[mask]

# Split data
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=y
)

# Train model
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# Evaluate
y_pred_proba = rf_model.predict_proba(X_test)[:, 1]
auc_score = roc_auc_score(y_test, y_pred_proba)

print(f"AUC Score: {auc_score:.3f}")

# Feature importance
feature_importance = pd.DataFrame({
    'feature': features,
    'importance': rf_model.feature_importances_
}).sort_values('importance', ascending=False)

print("\nTop 5 Most Important Features:")
print(feature_importance.head())
```

---

## üéØ Prescriptive Analytics
*"What should we do?" - ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏Å‡∏≤‡∏£‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£*

### üéØ **Customer Acquisition Strategy**

#### **7. ‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡πà‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢**
```python
# Q7: Customer segmentation for targeted marketing
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler

# Features for segmentation
segmentation_features = ['annual_inc', 'loan_amnt', 'dti', 'fico_range_low']

# Prepare data (remove NaN)
segment_data = df[segmentation_features].dropna()
scaler = StandardScaler()
scaled_data = scaler.fit_transform(segment_data)

# K-means clustering
kmeans = KMeans(n_clusters=4, random_state=42)
segment_labels = kmeans.fit_predict(scaled_data)

# Add segments back to original dataframe
segment_df = df[segmentation_features].dropna().copy()
segment_df['customer_segment'] = segment_labels

# Analyze segments
segment_analysis = segment_df.groupby('customer_segment').agg({
    'annual_inc': ['mean', 'median'],
    'loan_amnt': ['mean', 'median'],
    'fico_range_low': 'mean',
    'dti': 'mean'
}).round(2)

print("Customer Segments Analysis:")
print(segment_analysis)
```

### üîß **Operational Optimization**

#### **8. Credit Decision Automation**
```python
# Q8: ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏∞‡∏ö‡∏ö‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡πÄ‡∏Ñ‡∏£‡∏î‡∏¥‡∏ï‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
def automated_credit_decision(loan_application):
    """
    ‡∏£‡∏∞‡∏ö‡∏ö‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏≠‡∏ô‡∏∏‡∏°‡∏±‡∏ï‡∏¥‡∏™‡∏¥‡∏ô‡πÄ‡∏ä‡∏∑‡πà‡∏≠
    """
    score = 0
    decision_factors = []
    
    # FICO Score (40% weight)
    fico = loan_application.get('fico_score', 0)
    if fico >= 740:
        score += 40
        decision_factors.append("Excellent FICO score")
    elif fico >= 680:
        score += 30
        decision_factors.append("Good FICO score")
    elif fico >= 620:
        score += 20
        decision_factors.append("Fair FICO score")
    else:
        score += 0
        decision_factors.append("Poor FICO score - high risk")
    
    # DTI Ratio (25% weight)
    dti = loan_application.get('dti', 100)
    if dti <= 15:
        score += 25
        decision_factors.append("Low DTI ratio")
    elif dti <= 25:
        score += 20
        decision_factors.append("Moderate DTI ratio")
    elif dti <= 35:
        score += 10
        decision_factors.append("High DTI ratio")
    else:
        score += 0
        decision_factors.append("Very high DTI ratio - risk factor")
    
    # Income Verification (15% weight)
    verification = loan_application.get('verification_status', 'Not Verified')
    if verification == 'Verified':
        score += 15
        decision_factors.append("Income verified")
    elif verification == 'Source Verified':
        score += 10
        decision_factors.append("Income source verified")
    else:
        score += 0
        decision_factors.append("Income not verified")
    
    # Delinquency History (20% weight)
    delinq = loan_application.get('delinq_2yrs', 0)
    if delinq == 0:
        score += 20
        decision_factors.append("No recent delinquencies")
    elif delinq <= 2:
        score += 10
        decision_factors.append("Some recent delinquencies")
    else:
        score += 0
        decision_factors.append("Multiple delinquencies - major risk")
    
    # Make decision
    if score >= 80:
        decision = "APPROVE"
        suggested_rate = "Best rate tier"
    elif score >= 60:
        decision = "APPROVE"
        suggested_rate = "Standard rate tier"
    elif score >= 40:
        decision = "CONDITIONAL APPROVE"
        suggested_rate = "Higher rate tier + additional verification"
    else:
        decision = "DECLINE"
        suggested_rate = "N/A"
    
    return {
        'score': score,
        'decision': decision,
        'suggested_rate_tier': suggested_rate,
        'decision_factors': decision_factors
    }

# ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
sample_application = {
    'fico_score': 720,
    'dti': 18.5,
    'verification_status': 'Verified',
    'delinq_2yrs': 0
}

result = automated_credit_decision(sample_application)
print("Credit Decision Result:")
print(f"Score: {result['score']}/100")
print(f"Decision: {result['decision']}")
print(f"Rate Tier: {result['suggested_rate_tier']}")
```

---

## üìä Data Visualization Questions

### üìà **Executive Dashboard Questions**

#### **9. Risk Heatmap**
```python
# Q9: ‡∏™‡∏£‡πâ‡∏≤‡∏á Risk Heatmap
import matplotlib.pyplot as plt
import seaborn as sns

# Risk by State and Purpose (top states only)
top_states = df['addr_state'].value_counts().head(10).index
df_subset = df[df['addr_state'].isin(top_states)]

risk_matrix = pd.crosstab(
    df_subset['addr_state'], 
    df_subset['purpose'], 
    values=df_subset['is_bad_loan'], 
    aggfunc='mean'
) * 100

# Create heatmap
plt.figure(figsize=(12, 8))
sns.heatmap(risk_matrix, annot=True, cmap='RdYlBu_r', fmt='.1f')
plt.title('Default Rate (%) by State and Purpose')
plt.xlabel('Loan Purpose')
plt.ylabel('State')
plt.tight_layout()
plt.show()
```

#### **10. Performance Trends**
```python
# Q10: Monthly performance trends
monthly_trends = df.groupby(df['issue_d'].dt.to_period('M')).agg({
    'loan_amnt': ['count', 'sum'],
    'int_rate': 'mean',
    'is_bad_loan': 'mean'
}).round(3)

# Plot trends
fig, axes = plt.subplots(2, 2, figsize=(15, 10))

# Loan volume
monthly_trends['loan_amnt']['count'].plot(ax=axes[0,0], title='Monthly Loan Count')
monthly_trends['loan_amnt']['sum'].plot(ax=axes[0,1], title='Monthly Loan Amount ($)')
monthly_trends['int_rate']['mean'].plot(ax=axes[1,0], title='Average Interest Rate (%)')
monthly_trends['is_bad_loan']['mean'].plot(ax=axes[1,1], title='Default Rate')

plt.tight_layout()
plt.show()
```

---

## ü§ñ Machine Learning Applications

### üéØ **Classification Problems**

#### **11. Multi-class Loan Status Prediction**
```python
# Q11: ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢ loan status ‡πÅ‡∏ö‡∏ö multi-class
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report

# Define classes
status_mapping = {
    'Fully Paid': 0,
    'Current': 1,
    'Charged Off': 2,
    'Late (31-120 days)': 3,
    'Late (16-30 days)': 4,
    'In Grace Period': 5
}

# Prepare multi-class target
df_ml = df[df['loan_status'].isin(status_mapping.keys())].copy()
df_ml['status_code'] = df_ml['loan_status'].map(status_mapping)

# Features
features = [
    'loan_amnt', 'int_rate', 'installment', 'annual_inc', 'dti',
    'fico_range_low', 'revol_util', 'delinq_2yrs', 'inq_last_6mths',
    'open_acc', 'pub_rec'
]

# Prepare data
X = df_ml[features].fillna(df_ml[features].median())
y = df_ml['status_code']

# Remove any remaining NaN values
mask = ~(X.isnull().any(axis=1) | y.isnull())
X = X[mask]
y = y[mask]

# Train model
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=y
)

rf_multiclass = RandomForestClassifier(n_estimators=100, random_state=42)
rf_multiclass.fit(X_train, y_train)

y_pred_multi = rf_multiclass.predict(X_test)
print("Multi-class Classification Report:")
print(classification_report(y_test, y_pred_multi))
```

### üìä **Clustering Applications**

#### **12. Customer Lifetime Value Segmentation**
```python
# Q12: ‡πÅ‡∏ö‡πà‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏ï‡∏≤‡∏° CLV
# ‡∏™‡∏£‡πâ‡∏≤‡∏á customer-level aggregation (simplified version)
customer_features = df.groupby('member_id').agg({
    'loan_amnt': ['sum', 'count', 'mean'],
    'total_rec_int': 'sum',
    'is_bad_loan': 'mean',
    'int_rate': 'mean'
}).fillna(0)

# Flatten column names
customer_features.columns = ['total_borrowed', 'num_loans', 'avg_loan_size',
                           'total_interest_paid', 'default_rate', 'avg_interest_rate']

# Calculate CLV proxy
customer_features['clv_proxy'] = (
    customer_features['total_interest_paid'] - 
    customer_features['total_borrowed'] * customer_features['default_rate'] * 0.5
)

# Remove outliers and perform clustering
Q1 = customer_features['clv_proxy'].quantile(0.25)
Q3 = customer_features['clv_proxy'].quantile(0.75)
IQR = Q3 - Q1
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

customer_clean = customer_features[
    (customer_features['clv_proxy'] >= lower_bound) & 
    (customer_features['clv_proxy'] <= upper_bound)
]

# Clustering
cluster_features = ['total_borrowed', 'num_loans', 'total_interest_paid', 'default_rate']
scaler = StandardScaler()
scaled_clv = scaler.fit_transform(customer_clean[cluster_features])

kmeans_clv = KMeans(n_clusters=4, random_state=42)
customer_clean['clv_segment'] = kmeans_clv.fit_predict(scaled_clv)

# Analyze segments
clv_analysis = customer_clean.groupby('clv_segment').agg({
    'total_borrowed': 'mean',
    'num_loans': 'mean',
    'total_interest_paid': 'mean',
    'default_rate': 'mean',
    'clv_proxy': 'mean'
}).round(2)

print("Customer Lifetime Value Segments:")
print(clv_analysis)
```

---

## üíº Business Intelligence & KPIs

### üìä **Financial KPIs**

#### **13. ROI ‡πÅ‡∏•‡∏∞ Risk-Adjusted Returns**
```python
# Q13: ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì KPIs ‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏á‡∏¥‡∏ô‡∏´‡∏•‡∏±‡∏Å
def calculate_financial_kpis(df):
    """
    ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì KPIs ‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏á‡∏¥‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
    """
    kpis = {}
    
    # Portfolio Size
    kpis['total_loans'] = len(df)
    kpis['total_amount'] = df['loan_amnt'].sum()
    kpis['avg_loan_size'] = df['loan_amnt'].mean()
    
    # Risk Metrics
    kpis['default_rate'] = df['is_bad_loan'].mean()
    kpis['charge_off_rate'] = (df['loan_status'] == 'Charged Off').mean()
    
    # Profitability (for completed loans only)
    completed_loans = df[df['loan_status'].isin(['Fully Paid', 'Charged Off'])]
    if len(completed_loans) > 0:
        kpis['total_interest_income'] = completed_loans['total_rec_int'].sum()
        kpis['total_losses'] = completed_loans[
            completed_loans['is_bad_loan'] == 1
        ]['funded_amnt'].sum()
        
        # Net Interest Margin
        kpis['net_interest_margin'] = (
            kpis['total_interest_income'] - kpis['total_losses']
        ) / kpis['total_amount']
    else:
        kpis['total_interest_income'] = 0
        kpis['total_losses'] = 0
        kpis['net_interest_margin'] = 0
    
    return kpis

# ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÅ‡∏•‡∏∞‡πÅ‡∏™‡∏î‡∏á KPIs
financial_kpis = calculate_financial_kpis(df)

print("=== KEY FINANCIAL KPIs ===")
for kpi, value in financial_kpis.items():
    if isinstance(value, float):
        if 'rate' in kpi or 'margin' in kpi:
            print(f"{kpi}: {value:.2%}")
        else:
            print(f"{kpi}: ${value:,.2f}")
    else:
        print(f"{kpi}: {value:,}")
```

#### **14. Performance Benchmarking**
```python
# Q14: ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö performance ‡∏Å‡∏±‡∏ö benchmark
def benchmark_analysis(df, benchmark_default_rate=0.12, benchmark_nim=0.08):
    """
    ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö performance ‡∏Å‡∏±‡∏ö industry benchmark
    """
    actual_default_rate = df['is_bad_loan'].mean()
    
    # Calculate actual NIM (simplified)
    completed_loans = df[df['loan_status'].isin(['Fully Paid', 'Charged Off'])]
    if len(completed_loans) > 0:
        total_interest = completed_loans['total_rec_int'].sum()
        total_principal = completed_loans['funded_amnt'].sum()
        actual_nim = total_interest / total_principal if total_principal > 0 else 0
    else:
        actual_nim = 0
    
    benchmark_results = {
        'default_rate': {
            'actual': actual_default_rate,
            'benchmark': benchmark_default_rate,
            'variance': actual_default_rate - benchmark_default_rate,
            'performance': 'Better' if actual_default_rate < benchmark_default_rate else 'Worse'
        },
        'net_interest_margin': {
            'actual': actual_nim,
            'benchmark': benchmark_nim,
            'variance': actual_nim - benchmark_nim,
            'performance': 'Better' if actual_nim > benchmark_nim else 'Worse'
        }
    }
    
    return benchmark_results

benchmark_results = benchmark_analysis(df)

print("=== BENCHMARK ANALYSIS ===")
for metric, data in benchmark_results.items():
    print(f"\n{metric.upper()}:")
    print(f"  Actual: {data['actual']:.2%}")
    print(f"  Benchmark: {data['benchmark']:.2%}")
    print(f"  Variance: {data['variance']:.2%}")
    print(f"  Performance: {data['performance']}")
```

### üìà **Operational KPIs**

#### **15. Process Efficiency Metrics**
```python
# Q15: ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏Å‡∏≤‡∏£‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏á‡∏≤‡∏ô
def operational_efficiency_analysis(df):
    """
    ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå KPIs ‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏á‡∏≤‡∏ô
    """
    efficiency_metrics = {}
    
    # Funding Efficiency
    efficiency_metrics['funding_ratio'] = (
        df['funded_amnt'].sum() / df['loan_amnt'].sum()
    )
    
    # Portfolio Diversification
    purpose_distribution = df['purpose'].value_counts(normalize=True)
    efficiency_metrics['portfolio_concentration'] = purpose_distribution.iloc[0]
    
    # Grade Distribution Health
    grade_distribution = df['grade'].value_counts(normalize=True)
    efficiency_metrics['grade_a_b_ratio'] = (
        grade_distribution.get('A', 0) + grade_distribution.get('B', 0)
    )
    
    # Geographic Diversification
    state_distribution = df['addr_state'].value_counts(normalize=True)
    efficiency_metrics['geographic_concentration'] = state_distribution.iloc[0]
    
    # Verification Rate
    verification_rate = df['verification_status'].isin(['Verified', 'Source Verified']).mean()
    efficiency_metrics['verification_rate'] = verification_rate
    
    return efficiency_metrics

operational_kpis = operational_efficiency_analysis(df)

print("=== OPERATIONAL EFFICIENCY KPIs ===")
for kpi, value in operational_kpis.items():
    print(f"{kpi}: {value:.2%}")
```

---

## üéì ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏¢‡∏∏‡∏Å‡∏ï‡πå‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£

### üìö **‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà 1: Essential Data Analytics**
- Questions 1-3: Descriptive Analytics
- Questions 9-10: Basic Visualizations
- Focus: ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•, ‡∏™‡∏£‡πâ‡∏≤‡∏á insights ‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô

### üìä **‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà 2: Data Profiling & Preparation**
- Questions 4-5: Diagnostic Analytics
- Questions 13-15: KPI Development
- Focus: ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•, ‡∏™‡∏£‡πâ‡∏≤‡∏á features

### ü§ñ **‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà 3: Predictive Analytics & ML**
- Questions 6-8: Predictive & Prescriptive Analytics
- Questions 11-12: Advanced ML Applications
- Focus: ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•, ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏¢‡∏∏‡∏Å‡∏ï‡πå‡πÉ‡∏ä‡πâ

### üí° **‡πÄ‡∏Ñ‡∏•‡πá‡∏î‡∏•‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡πÇ‡∏à‡∏ó‡∏¢‡πå**

1. **‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å‡∏á‡πà‡∏≤‡∏¢‡πÑ‡∏õ‡∏¢‡∏≤‡∏Å**: ‡πÉ‡∏ä‡πâ descriptive ‡∏Å‡πà‡∏≠‡∏ô ‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡πà‡∏≠‡∏¢‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô
2. **‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡πÇ‡∏¢‡∏á‡∏Å‡∏±‡∏ö‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à**: ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ business impact ‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞ analysis
3. **‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á**: ‡∏¢‡∏Å‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Lending Club
4. **‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå**: ‡πÉ‡∏ä‡πâ‡∏´‡∏•‡∏≤‡∏¢‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£ validate insights
5. **‡∏™‡∏£‡πâ‡∏≤‡∏á narrative**: ‡πÄ‡∏•‡πà‡∏≤‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡∏ô‡πà‡∏≤‡∏™‡∏ô‡πÉ‡∏à

### üéØ **‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡πÉ‡∏ä‡πâ‡∏ï‡∏≤‡∏°‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏Å**

#### **‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô (Beginner)**
- Questions 1-3, 9: Basic descriptive analysis
- ‡πÄ‡∏ô‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ pandas groupby, basic plotting
- ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏Å‡∏≤‡∏£‡∏ï‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•

#### **‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Å‡∏•‡∏≤‡∏á (Intermediate)**
- Questions 4-5, 10-11: Statistical analysis, advanced visualization
- ‡πÄ‡∏ô‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ statistical tests, cohort analysis
- ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏Å‡∏≤‡∏£‡∏´‡∏≤‡∏™‡∏≤‡πÄ‡∏´‡∏ï‡∏∏‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå

#### **‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏™‡∏π‡∏á (Advanced)**
- Questions 6-8, 12-15: Machine learning, optimization
- ‡πÄ‡∏ô‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• ML, business optimization
- ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏∞‡∏ö‡∏ö‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥

---

*üìñ ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏: ‡πÇ‡∏à‡∏ó‡∏¢‡πå‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡∏°‡∏≤‡πÉ‡∏´‡πâ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏ó‡∏∏‡∏Å‡∏î‡πâ‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡πÅ‡∏•‡∏∞‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏±‡∏ö‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏Å‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô*

---
[‚¨ÖÔ∏è ‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡∏ó‡∏µ‡πà Key Variables](./04_key_variables.md) | [‚û°Ô∏è ‡πÑ‡∏õ‡∏¢‡∏±‡∏á Case Studies](./06_case_studies.md)