# üöÄ ‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô LoanStats_web_14422.csv ‡πÉ‡∏ô Google Colab

## üìã ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏£‡πâ‡∏≠‡∏°

### 1Ô∏è‚É£ ‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô Google Drive

**‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏° Lab ‡πÉ‡∏î‡πÜ ‡πÉ‡∏´‡πâ‡∏ó‡∏≥‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡∏Å‡πà‡∏≠‡∏ô:**

1. **‡πÄ‡∏Ç‡πâ‡∏≤ Google Drive** 
   - ‡πÑ‡∏õ‡∏ó‡∏µ‡πà [drive.google.com](https://drive.google.com)
   - ‡πÉ‡∏ä‡πâ Google Account ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÉ‡∏ä‡πâ Colab

2. **‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå**
   ```
   MyDrive/
   ‚îî‚îÄ‚îÄ NT_Python_for_Data_Analytics/
       ‚îî‚îÄ‚îÄ LoanStats_web_14422.csv  ‚Üê ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏ô‡∏µ‡πâ
   ```

3. **‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•**
   - ‡πÄ‡∏õ‡∏¥‡∏î Google Colab ‡πÉ‡∏´‡∏°‡πà
   - ‡∏ó‡∏î‡∏™‡∏≠‡∏ö mount drive ‡πÅ‡∏•‡∏∞‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•

### **üìö ‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞ Lab**

1. **‡πÄ‡∏õ‡∏¥‡∏î Notebook ‡∏à‡∏≤‡∏Å README.md**
   - ‡∏Ñ‡∏•‡∏¥‡∏Å [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)] badge
   - ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ‡∏•‡∏¥‡∏á‡∏Ñ‡πå‡πÉ‡∏ô README

2. **‡∏£‡∏±‡∏ô‡∏™‡πà‡∏ß‡∏ô Setup ‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏™‡∏°‡∏≠**
   ```python
   # Standard setup code
   from google.colab import drive
   import pandas as pd
   import numpy as np
   import matplotlib.pyplot as plt
   import seaborn as sns
   
   # Mount drive
   drive.mount('/content/drive')
   
   # Load data
   DATA_PATH = '/content/drive/MyDrive/NT_Python_for_Data_Analytics/LoanStats_web_14422.csv'
   df_loan = pd.read_csv(DATA_PATH, low_memory=False)
   
   print(f"‚úÖ Data loaded: {df_loan.shape}")
   ```

3. **‡πÉ‡∏ä‡πâ Template Functions (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Module 2)**
   - Copy functions ‡∏à‡∏≤‡∏Å `LAB_TEMPLATES.md`
   - ‡πÉ‡∏ä‡πâ `quick_profile(df_loan)` ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö overview
   - ‡πÉ‡∏ä‡πâ `analyze_column('column_name')` ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå

---

## üéØ ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÉ‡∏ô Labs ‡πÅ‡∏ï‡πà‡∏•‡∏∞ Module

### **üìÅ Module 1: Essential Data Analytics & Basic Python**

**Lab 01a-01e: ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á**
```python
# ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô
print(f"üìä ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Lending Club ‡∏°‡∏µ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î {len(df_loan):,} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏™‡∏¥‡∏ô‡πÄ‡∏ä‡∏∑‡πà‡∏≠")
print(f"üìã ‡∏°‡∏µ {len(df_loan.columns)} ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå")

# ‡∏î‡∏π‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á
print("\nüîç ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• 5 ‡πÅ‡∏ñ‡∏ß‡πÅ‡∏£‡∏Å:")
df_loan.head()

# ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô
if 'loan_amnt' in df_loan.columns:
    print(f"\nüí∞ ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏á‡∏¥‡∏ô‡∏Å‡∏π‡πâ‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢: ${df_loan['loan_amnt'].mean():,.2f}")
    print(f"üí∞ ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏á‡∏¥‡∏ô‡∏Å‡∏π‡πâ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î: ${df_loan['loan_amnt'].max():,.2f}")
```

### **üìÅ Module 2: Data Profiling & Preparation**

**Lab 02a: Pandas DataFrame**
```python
# ‡∏Å‡∏≤‡∏£‡∏™‡∏≥‡∏£‡∏ß‡∏à DataFrame structure
print("üìä DataFrame Information:")
print(f"Shape: {df_loan.shape}")
print(f"Memory usage: {df_loan.memory_usage(deep=True).sum()/1024**2:.1f} MB")
print(f"Data types: {df_loan.dtypes.value_counts().to_dict()}")

# ‡∏î‡∏π‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
print(f"\nüìã All columns ({len(df_loan.columns)}):")
for i, col in enumerate(df_loan.columns, 1):
    print(f"{i:3d}. {col}")
```

**Lab 02d: Data Profiling Workshop**
```python
# ‡πÉ‡∏ä‡πâ comprehensive_data_profile function ‡∏à‡∏≤‡∏Å templates
from LAB_TEMPLATES import comprehensive_data_profile

# ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ function ‡πÅ‡∏ö‡∏ö‡∏á‡πà‡∏≤‡∏¢
def quick_loan_profile(df):
    print("üè¶ LENDING CLUB DATA PROFILE")
    print("="*40)
    
    # Basic stats
    print(f"üìä Total loans: {len(df):,}")
    print(f"üìä Features: {len(df.columns)}")
    print(f"üìä Missing values: {df.isnull().sum().sum():,}")
    
    # Key columns analysis
    key_cols = ['loan_amnt', 'int_rate', 'grade', 'loan_status']
    available_cols = [col for col in key_cols if col in df.columns]
    
    print(f"\nüîë Key columns available: {available_cols}")
    
    for col in available_cols:
        if df[col].dtype == 'object':
            print(f"\nüìù {col}: {df[col].nunique()} unique values")
            print(f"   Top 3: {df[col].value_counts().head(3).to_dict()}")
        else:
            print(f"\nüî¢ {col}: ${df[col].mean():,.2f} average")
            print(f"   Range: ${df[col].min():,.2f} - ${df[col].max():,.2f}")

quick_loan_profile(df_loan)
```

**Lab 02h-02i: Correlation Analysis**
```python
# ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå
key_numeric = ['loan_amnt', 'int_rate', 'annual_inc', 'dti']
available_numeric = [col for col in key_numeric if col in df_loan.columns]

if len(available_numeric) >= 2:
    # Correlation matrix
    df_analysis = df_loan[available_numeric].copy()
    corr_matrix = df_analysis.corr()
    
    # Visualization
    plt.figure(figsize=(10, 8))
    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)
    plt.title('Correlation Matrix - Key Lending Variables')
    plt.show()
    
    # ‡∏´‡∏≤ correlation ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î
    if 'int_rate' in corr_matrix.columns:
        int_rate_corr = corr_matrix['int_rate'].sort_values(ascending=False)
        print("üîó Correlation with Interest Rate:")
        print(int_rate_corr)
else:
    print("‚ùå Not enough numeric columns for correlation analysis")
```

### **üìÅ Module 3: Machine Learning**

**Lab 03c: Classification (Loan Default Prediction)**
```python
# ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Classification
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report
from sklearn.preprocessing import LabelEncoder

# ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡πÅ‡∏•‡∏∞ target
features = ['loan_amnt', 'int_rate', 'annual_inc', 'dti']
target = 'loan_status'

# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
available_features = [col for col in features if col in df_loan.columns]
has_target = target in df_loan.columns

print(f"üéØ Available features: {available_features}")
print(f"üéØ Target available: {has_target}")

if has_target and len(available_features) >= 2:
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á working dataset
    df_work = df_loan[available_features + [target]].copy()
    
    # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• - ‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞ loan ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô
    good_loans = ['Fully Paid', 'Current']
    bad_loans = ['Charged Off', 'Default']
    
    df_work = df_work[df_work[target].isin(good_loans + bad_loans)]
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á binary target (0 = Good, 1 = Bad)
    df_work['default'] = df_work[target].apply(
        lambda x: 0 if x in good_loans else 1
    )
    
    print(f"\nüìä Dataset after cleaning: {df_work.shape}")
    print(f"üìä Default rate: {df_work['default'].mean()*100:.1f}%")
    
    # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö modeling
    X = df_work[available_features].fillna(df_work[available_features].median())
    y = df_work['default']
    
    # ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    print(f"\n‚úÖ Data ready for classification:")
    print(f"   Training set: {X_train.shape}")
    print(f"   Test set: {X_test.shape}")
    print(f"   Features: {list(X.columns)}")
    
    # Quick model training
    rf = RandomForestClassifier(n_estimators=50, random_state=42)
    rf.fit(X_train, y_train)
    
    # Predictions
    y_pred = rf.predict(X_test)
    
    print(f"\nüìä Classification Results:")
    print(classification_report(y_test, y_pred))
    
    # Feature importance
    importance_df = pd.DataFrame({
        'feature': X.columns,
        'importance': rf.feature_importances_
    }).sort_values('importance', ascending=False)
    
    print(f"\nüîù Feature Importance:")
    print(importance_df)
    
else:
    print("‚ùå Missing required columns for classification")
    print(f"Available columns: {list(df_loan.columns[:20])}...")
```

**Lab 03e: Regression (Interest Rate Prediction)**
```python
# ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Regression
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

# ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡πÅ‡∏•‡∏∞ target ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö regression
features = ['loan_amnt', 'annual_inc', 'dti']
target = 'int_rate'

available_features = [col for col in features if col in df_loan.columns]
has_target = target in df_loan.columns

print(f"üìà Regression setup:")
print(f"   Features: {available_features}")
print(f"   Target: {target} ({'‚úÖ' if has_target else '‚ùå'})")

if has_target and len(available_features) >= 2:
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á working dataset
    df_reg = df_loan[available_features + [target]].dropna()
    
    print(f"\nüìä Dataset for regression: {df_reg.shape}")
    print(f"üìä Target statistics:")
    print(df_reg[target].describe())
    
    # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    X = df_reg[available_features]
    y = df_reg[target]
    
    # ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )
    
    # Train model
    lr = LinearRegression()
    lr.fit(X_train, y_train)
    
    # Predictions
    y_pred = lr.predict(X_test)
    
    # Evaluate
    r2 = r2_score(y_test, y_pred)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    
    print(f"\nüìä Regression Results:")
    print(f"   R¬≤ Score: {r2:.3f}")
    print(f"   RMSE: {rmse:.3f}")
    
    # Coefficients
    coef_df = pd.DataFrame({
        'feature': X.columns,
        'coefficient': lr.coef_
    }).sort_values('coefficient', key=abs, ascending=False)
    
    print(f"\nüîç Model Coefficients:")
    print(coef_df)
    
    # Simple visualization
    plt.figure(figsize=(10, 6))
    plt.scatter(y_test, y_pred, alpha=0.5)
    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
    plt.xlabel('Actual Interest Rate')
    plt.ylabel('Predicted Interest Rate')
    plt.title(f'Actual vs Predicted (R¬≤ = {r2:.3f})')
    plt.show()
    
else:
    print("‚ùå Missing required columns for regression")
```

---

## üîß Troubleshooting ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏à‡∏û‡∏ö

### **‚ùå ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ**

1. **"FileNotFoundError: LoanStats_web_14422.csv"**
   ```python
   # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô Drive
   import os
   files = os.listdir('/content/drive/MyDrive/NT_Python_for_Data_Analytics/')
   print("Files found:", files)
   ```

2. **"Drive not mounted"**
   ```python
   # Mount ‡πÉ‡∏´‡∏°‡πà
   from google.colab import drive
   drive.mount('/content/drive', force_remount=True)
   ```

3. **"Memory Error" ‡∏´‡∏£‡∏∑‡∏≠ "Out of Memory"**
   ```python
   # ‡πÉ‡∏ä‡πâ sample ‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
   important_cols = ['loan_amnt', 'int_rate', 'grade', 'loan_status', 'annual_inc']
   df_small = pd.read_csv(DATA_PATH, usecols=important_cols)
   
   # ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ sample
   df_sample = df_loan.sample(n=5000)  # ‡πÉ‡∏ä‡πâ 5000 ‡πÅ‡∏ñ‡∏ß
   ```

4. **"Column not found"**
   ```python
   # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏à‡∏£‡∏¥‡∏á
   print("Available columns:")
   for i, col in enumerate(df_loan.columns):
       print(f"{i+1:3d}. {col}")
   
   # ‡∏´‡∏≤‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
   search_term = 'loan'
   matching_cols = [col for col in df_loan.columns if search_term.lower() in col.lower()]
   print(f"Columns containing '{search_term}': {matching_cols}")
   ```

5. **"Performance Issues"**
   ```python
   # ‡πÉ‡∏ä‡πâ sample ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö
   df_test = df_loan.sample(n=1000)
   
   # ‡∏•‡∏î memory usage
   df_loan = df_loan.select_dtypes(exclude=['object'])  # ‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç
   
   # Clear memory
   del df_sample
   import gc
   gc.collect()
   ```

---

## üìù ‡∏™‡∏£‡∏∏‡∏õ‡πÅ‡∏•‡∏∞‡πÄ‡∏Ñ‡∏•‡πá‡∏î‡∏•‡∏±‡∏ö‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç

### **‚úÖ ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏£‡∏à‡∏≥**
1. **‡πÄ‡∏™‡∏°‡∏≠ mount Google Drive ‡∏Å‡πà‡∏≠‡∏ô** ‡πÉ‡∏ô‡∏ó‡∏∏‡∏Å notebook
2. **‡πÉ‡∏ä‡πâ path ‡∏ó‡∏µ‡πà‡∏™‡∏°‡πà‡∏≥‡πÄ‡∏™‡∏°‡∏≠**: `/content/drive/MyDrive/NT_Python_for_Data_Analytics/`
3. **‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡πà‡∏≠‡∏ô‡πÉ‡∏ä‡πâ**: `.shape`, `.info()`, `.head()`, `.columns`
4. **‡πÉ‡∏ä‡πâ sample ‡∏Ç‡∏ì‡∏∞‡∏û‡∏±‡∏í‡∏ô‡∏≤**: `df.sample(n=1000)` ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß
5. **‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ missing data ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°**: `.dropna()`, `.fillna()`
6. **‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏á‡∏≤‡∏ô**: save ‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡∏¢‡∏±‡∏á Google Drive
7. **‡∏•‡πâ‡∏≤‡∏á memory ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô**: `del variable; gc.collect()`

### **üéØ Best Practices**
- ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏î‡πâ‡∏ß‡∏¢ sample ‡πÄ‡∏•‡πá‡∏Å‡πÜ ‡πÄ‡∏™‡∏°‡∏≠
- ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡πà‡∏≠‡∏ô‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå
- ‡πÉ‡∏ä‡πâ visualization ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
- ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô code ‡∏ó‡∏µ‡πà‡∏≠‡πà‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢ ‡∏°‡∏µ comment
- ‡πÄ‡∏Å‡πá‡∏ö notebook ‡∏ó‡∏µ‡πà‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡πÑ‡∏ß‡πâ‡πÉ‡∏ô Drive

### **üöÄ Next Steps**
1. ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£ setup ‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á
2. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° environment ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ô‡∏±‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏ô
3. ‡∏™‡∏£‡πâ‡∏≤‡∏á backup plans ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏à‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡∏∂‡πâ‡∏ô
4. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏™‡∏£‡∏¥‡∏°‡∏´‡∏≤‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£

---

**üéì ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏≠‡∏ô Course 250FDEV01C00 ‡πÅ‡∏•‡πâ‡∏ß!**

*‡∏´‡∏≤‡∏Å‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏° ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å COLAB_SETUP_GUIDE.md ‡πÅ‡∏•‡∏∞ LAB_TEMPLATES.md ‡∏ó‡∏µ‡πà‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÑ‡∏ß‡πâ*rive/
   ‚îî‚îÄ‚îÄ NT_Python_for_Data_Analytics/
       ‚îî‚îÄ‚îÄ LoanStats_web_14422.csv  ‚Üê ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏ô‡∏µ‡πâ
   ```

3. **‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå**
   - ‡∏•‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå `LoanStats_web_14422.csv` ‡πÑ‡∏õ‡πÉ‡∏ô Google Drive
   - ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ‡∏õ‡∏∏‡πà‡∏° "New" > "File upload"

### 2Ô∏è‚É£ ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÉ‡∏ô Google Colab

#### üîó Template Code (‡πÉ‡∏™‡πà‡πÉ‡∏ô‡∏ó‡∏∏‡∏Å Lab)

```python
# üöÄ Standard Setup ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏∏‡∏Å Lab
from google.colab import drive
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Mount Google Drive
drive.mount('/content/drive')

# ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
DATA_PATH = '/content/drive/MyDrive/NT_Python_for_Data_Analytics/LoanStats_web_14422.csv'
df_loan = pd.read_csv(DATA_PATH, low_memory=False)

print(f"‚úÖ Data loaded: {df_loan.shape[0]:,} rows √ó {df_loan.shape[1]:,} columns")
```

---

## üìö ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÉ‡∏ô Labs ‡πÅ‡∏ï‡πà‡∏•‡∏∞ Module

### üìÅ Module 1: Essential Data Analytics & Basic Python

**Lab 01a-01e: ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô**
```python
# ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô
print("üìä ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Lending Club")
print(f"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏™‡∏¥‡∏ô‡πÄ‡∏ä‡∏∑‡πà‡∏≠: {len(df_loan):,} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
print(f"‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {len(df_loan.columns)} ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå")

# ‡∏î‡∏π‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á
df_loan.head()
```

### üìÅ Module 2: Data Profiling & Preparation

#### **Lab 02a: Pandas DataFrame**
```python
# ‡∏Å‡∏≤‡∏£‡∏™‡∏≥‡∏£‡∏ß‡∏à DataFrame
print("üìä DataFrame Info:")
print(f"Shape: {df_loan.shape}")
print(f"Memory usage: {df_loan.memory_usage(deep=True).sum()/1024**2:.1f} MB")

# ‡∏î‡∏π‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
df_loan.dtypes.value_counts()
```

#### **Lab 02d: Data Profiling**
```python
# Data Profiling ‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô
def quick_profile(df):
    print("üîç Data Profile Summary")
    print("="*40)
    print(f"Rows: {df.shape[0]:,}")
    print(f"Columns: {df.shape[1]:,}")
    print(f"Missing values: {df.isnull().sum().sum():,}")
    print(f"Duplicates: {df.duplicated().sum():,}")
    
    # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç vs ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    text_cols = df.select_dtypes(include=['object']).columns
    
    print(f"Numeric columns: {len(numeric_cols)}")
    print(f"Text columns: {len(text_cols)}")
    
    return df.describe()

# ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
stats = quick_profile(df_loan)
```

---

## üîß Troubleshooting

### ‚ùå ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏ö‡πà‡∏≠‡∏¢

1. **"No such file or directory"**
   ```python
   # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö path
   import os
   path = '/content/drive/MyDrive/NT_Python_for_Data_Analytics/'
   print("Files in directory:")
   print(os.listdir(path))
   ```

2. **"Drive not mounted"**
   ```python
   # Mount ‡πÉ‡∏´‡∏°‡πà
   from google.colab import drive
   drive.mount('/content/drive', force_remount=True)
   ```

3. **"Memory error"**
   ```python
   # ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ö‡∏≤‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå
   important_cols = ['loan_amnt', 'int_rate', 'grade', 'loan_status']
   df_small = pd.read_csv(DATA_PATH, usecols=important_cols)
   ```

### ‚úÖ ‡πÄ‡∏Ñ‡∏•‡πá‡∏î‡∏•‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô

1. **‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡πà‡∏≠‡∏ô‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô**
   ```python
   print(f"Shape: {df_loan.shape}")
   print(f"Columns: {list(df_loan.columns[:10])}")  # ‡πÅ‡∏™‡∏î‡∏á 10 ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÅ‡∏£‡∏Å
   ```

2. **‡πÉ‡∏ä‡πâ sample ‡∏Ç‡∏ì‡∏∞‡∏ó‡∏î‡∏™‡∏≠‡∏ö**
   ```python
   df_sample = df_loan.sample(n=1000)  # ‡πÉ‡∏ä‡πâ sample ‡∏Ç‡∏ì‡∏∞ develop
   ```

3. **‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ memory**
   ```python
   # ‡∏•‡∏ö‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ
   del df_sample
   import gc
   gc.collect()
   ```

4. **‡πÄ‡∏ã‡∏ü‡∏ú‡∏•‡∏á‡∏≤‡∏ô**
   ```python
   # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡∏¢‡∏±‡∏á Drive
   df_result.to_csv('/content/drive/MyDrive/NT_Python_for_Data_Analytics/results.csv')
   ```

---

## üì± Quick Reference Commands

### üîÑ Essential Commands
```python
# Mount Drive
from google.colab import drive
drive.mount('/content/drive')

# Load Data
df = pd.read_csv('/content/drive/MyDrive/NT_Python_for_Data_Analytics/LoanStats_web_14422.csv')

# Quick Info
print(f"Shape: {df.shape}")
print(f"Columns: {df.columns.tolist()[:10]}")
print(f"Missing: {df.isnull().sum().sum()}")

# Sample Data
df_sample = df.sample(1000)
```

### üìä Quick Analysis
```python
# Descriptive Stats
df.describe()

# Missing Data
df.isnull().sum().sort_values(ascending=False).head(10)

# Correlation
df.corr()['target_column'].sort_values(ascending=False)

# Value Counts
df['categorical_column'].value_counts()
```

### üé® Quick Plots
```python
# Distribution
df['column'].hist(bins=50)
plt.show()

# Correlation Heatmap
sns.heatmap(df.corr(), annot=True)
plt.show()

# Box Plot
df.boxplot(column='numeric_column', by='categorical_column')
plt.show()
```

---

## üéØ ‡∏™‡∏£‡∏∏‡∏õ Best Practices

1. **‡πÄ‡∏™‡∏°‡∏≠ mount Drive ‡∏Å‡πà‡∏≠‡∏ô** ‡πÉ‡∏ô‡∏ó‡∏∏‡∏Å notebook
2. **‡πÉ‡∏ä‡πâ path ‡∏ó‡∏µ‡πà‡∏™‡∏°‡πà‡∏≥‡πÄ‡∏™‡∏°‡∏≠** `/content/drive/MyDrive/NT_Python_for_Data_Analytics/`
3. **‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡πà‡∏≠‡∏ô‡πÉ‡∏ä‡πâ** ‡∏î‡πâ‡∏ß‡∏¢ `.shape`, `.info()`, `.head()`
4. **‡πÉ‡∏ä‡πâ sample ‡∏Ç‡∏ì‡∏∞‡∏û‡∏±‡∏í‡∏ô‡∏≤** ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß
5. **‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ missing data** ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°
6. **‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏á‡∏≤‡∏ô** ‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡∏¢‡∏±‡∏á Drive
7. **‡∏•‡πâ‡∏≤‡∏á memory** ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏ï‡πà‡∏•‡∏∞ task

üéì **Happy Learning with Course 250FDEV01C00!**

---

*‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏° ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡∏ú‡∏π‡πâ‡∏™‡∏≠‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡∏î‡∏π‡πÉ‡∏ô course materials*