{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03b: Classification Algorithms\n",
    "\n",
    "## วัตถุประสงค์การเรียนรู้\n",
    "- เข้าใจหลักการของ Classification algorithms\n",
    "- รู้จัก Logistic Regression, Decision Trees, Random Forest\n",
    "- เข้าใจ metrics สำหรับ Classification\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Classification คืออะไร?\n",
    "\n",
    "- การทำนายหมวดหมู่ (class/category) ของข้อมูล\n",
    "- ผลลัพธ์เป็นค่าแบบแยกส่วน (discrete)\n",
    "- **Binary**: 2 คลาส (ใช่/ไม่ใช่)\n",
    "- **Multiclass**: หลายคลาส (A/B/C/D)\n",
    "\n",
    "### ตัวอย่างการใช้งาน\n",
    "- Email Spam Detection\n",
    "- Medical Diagnosis\n",
    "- Customer Segmentation\n",
    "- Image Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_classification, load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# สร้างข้อมูลตัวอย่าง Binary Classification\n",
    "np.random.seed(42)\n",
    "X, y = make_classification(n_samples=300, n_features=2, n_redundant=0, \n",
    "                          n_informative=2, n_clusters_per_class=1, random_state=42)\n",
    "\n",
    "# แสดงข้อมูล\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X[y==0, 0], X[y==0, 1], c='red', marker='o', label='Class 0')\n",
    "plt.scatter(X[y==1, 0], X[y==1, 1], c='blue', marker='s', label='Class 1')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.title('Binary Classification Data')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"จำนวนข้อมูล: {X.shape[0]}\")\n",
    "print(f\"จำนวน Features: {X.shape[1]}\")\n",
    "print(f\"การกระจายของ Classes: {np.bincount(y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Logistic Regression\n",
    "\n",
    "### หลักการ\n",
    "- ใช้ Sigmoid function เพื่อแปลงค่าเป็นความน่าจะเป็น (0-1)\n",
    "- เหมาะสำหรับ Binary Classification\n",
    "- ตีความได้ง่าย\n",
    "- เร็วในการฝึกและทำนาย\n",
    "\n",
    "### Sigmoid Function\n",
    "σ(z) = 1 / (1 + e^(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# แบ่งข้อมูล\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# สร้างและฝึก Logistic Regression\n",
    "lr_model = LogisticRegression(random_state=42)\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# ทำนาย\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "y_prob_lr = lr_model.predict_proba(X_test)[:, 1]  # ความน่าจะเป็นของ class 1\n",
    "\n",
    "print(\"Logistic Regression Results:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_lr):.3f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# แสดง Decision Boundary\n",
    "def plot_decision_boundary(model, X, y, title):\n",
    "    h = 0.02\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    \n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    plt.contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.RdYlBu)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.RdYlBu, edgecolors='black')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Feature 1')\n",
    "    plt.ylabel('Feature 2')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plot_decision_boundary(lr_model, X, y, 'Logistic Regression Decision Boundary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Decision Trees\n",
    "\n",
    "### หลักการ\n",
    "- สร้างต้นไม้การตัดสินใจ\n",
    "- แบ่งข้อมูลตาม features ที่ให้ information gain สูงสุด\n",
    "- ตีความได้ง่าย\n",
    "- จัดการ categorical และ numerical data ได้\n",
    "\n",
    "### ข้อดี/ข้อเสีย\n",
    "- **ข้อดี**: ตีความง่าย, ไม่ต้อง preprocessing มาก\n",
    "- **ข้อเสีย**: ง่ายต่อ overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "\n",
    "# สร้างและฝึก Decision Tree\n",
    "dt_model = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# ทำนาย\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "\n",
    "print(\"Decision Tree Results:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_dt):.3f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# แสดงโครงสร้างของ Decision Tree\n",
    "plt.figure(figsize=(15, 8))\n",
    "plot_tree(dt_model, filled=True, feature_names=['Feature 1', 'Feature 2'], \n",
    "          class_names=['Class 0', 'Class 1'], fontsize=10)\n",
    "plt.title('Decision Tree Structure')\n",
    "plt.show()\n",
    "\n",
    "# แสดง Decision Boundary\n",
    "plt.figure(figsize=(10, 6))\n",
    "plot_decision_boundary(dt_model, X, y, 'Decision Tree Decision Boundary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Random Forest\n",
    "\n",
    "### หลักการ\n",
    "- Ensemble method ที่รวม Decision Trees หลายๆ ต้น\n",
    "- แต่ละต้นใช้ข้อมูลย่อยและ features ย่อย\n",
    "- ลดปัญหา overfitting\n",
    "- ให้ผลลัพธ์ที่แม่นยำกว่า single tree\n",
    "\n",
    "### ข้อดี\n",
    "- ความแม่นยำสูง\n",
    "- จัดการ missing values ได้\n",
    "- ให้ feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# สร้างและฝึก Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, max_depth=3, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# ทำนาย\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "print(\"Random Forest Results:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_rf):.3f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "\n",
    "# Feature Importance\n",
    "feature_importance = rf_model.feature_importances_\n",
    "print(\"\\nFeature Importance:\")\n",
    "for i, importance in enumerate(feature_importance):\n",
    "    print(f\"Feature {i+1}: {importance:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# เปรียบเทียบ Decision Boundaries ของแต่ละ algorithm\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "models = [lr_model, dt_model, rf_model]\n",
    "titles = ['Logistic Regression', 'Decision Tree', 'Random Forest']\n",
    "\n",
    "for i, (model, title) in enumerate(zip(models, titles)):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plot_decision_boundary(model, X, y, title)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Classification Metrics\n",
    "\n",
    "### หลัก Metrics\n",
    "- **Accuracy**: ความถูกต้องโดยรวม\n",
    "- **Precision**: ความแม่นยำของการทำนาย positive\n",
    "- **Recall**: ความครอบคลุมของ positive cases\n",
    "- **F1-Score**: ค่าเฉลี่ยของ Precision และ Recall\n",
    "\n",
    "### Confusion Matrix\n",
    "- แสดงผลการจำแนกแต่ละคลาส\n",
    "- ช่วยวิเคราะห์ข้อผิดพลาด"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "# คำนวณ metrics สำหรับแต่ละ model\n",
    "models_results = {\n",
    "    'Logistic Regression': y_pred_lr,\n",
    "    'Decision Tree': y_pred_dt,\n",
    "    'Random Forest': y_pred_rf\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame()\n",
    "\n",
    "for name, predictions in models_results.items():\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    precision = precision_score(y_test, predictions)\n",
    "    recall = recall_score(y_test, predictions)\n",
    "    f1 = f1_score(y_test, predictions)\n",
    "    \n",
    "    results_df[name] = [accuracy, precision, recall, f1]\n",
    "\n",
    "results_df.index = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "print(\"Model Comparison:\")\n",
    "print(results_df.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# แสดง Confusion Matrix\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "for i, (name, predictions) in enumerate(models_results.items()):\n",
    "    cm = confusion_matrix(y_test, predictions)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[i])\n",
    "    axes[i].set_title(f'{name}\\nConfusion Matrix')\n",
    "    axes[i].set_xlabel('Predicted')\n",
    "    axes[i].set_ylabel('Actual')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## สรุป\n",
    "\n",
    "### Classification Algorithms\n",
    "- **Logistic Regression**: เร็ว, ตีความได้, เหมาะกับ linear data\n",
    "- **Decision Tree**: ตีความง่าย, จัดการ non-linear ได้\n",
    "- **Random Forest**: ความแม่นยำสูง, ลด overfitting\n",
    "\n",
    "### Metrics\n",
    "- **Accuracy**: สำหรับ balanced data\n",
    "- **Precision/Recall**: สำหรับ imbalanced data\n",
    "- **F1-Score**: สมดุลระหว่าง Precision และ Recall\n",
    "\n",
    "### Next: Classification LAB"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}