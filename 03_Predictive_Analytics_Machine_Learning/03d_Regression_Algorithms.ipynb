{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03d: Regression Algorithms\n",
    "\n",
    "## วัตถุประสงค์การเรียนรู้\n",
    "- เข้าใจหลักการของ Regression algorithms\n",
    "- รู้จัก Linear, Polynomial, Ridge, Lasso และ Random Forest Regression\n",
    "- เข้าใจ metrics สำหรับ Regression\n",
    "- สามารถเลือกใช้อัลกอริทึมที่เหมาะสม\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Regression คืออะไร?\n",
    "\n",
    "- การทำนายค่าต่อเนื่อง (continuous values)\n",
    "- ผลลัพธ์เป็นตัวเลข (ไม่ใช่หมวดหมู่)\n",
    "- ตัวอย่าง: ราคาบ้าน, อุณหภูมิ, อัตราดอกเบี้ย\n",
    "\n",
    "### การใช้งาน\n",
    "- Price Prediction\n",
    "- Sales Forecasting  \n",
    "- Risk Assessment\n",
    "- Time Series Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# สร้างข้อมูลตัวอย่าง\n",
    "np.random.seed(42)\n",
    "X, y = make_regression(n_samples=300, n_features=1, noise=20, random_state=42)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X, y, alpha=0.6)\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Target')\n",
    "plt.title('Regression Sample Data')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"จำนวนข้อมูล: {X.shape[0]}\")\n",
    "print(f\"Target range: {y.min():.2f} to {y.max():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Linear Regression\n",
    "\n",
    "### หลักการ\n",
    "- หาเส้นตรงที่ fit กับข้อมูลดีที่สุด\n",
    "- สมการ: y = mx + b\n",
    "- ใช้ Least Squares method\n",
    "- เร็ว, ง่าย, ตีความได้\n",
    "\n",
    "### ข้อดี/ข้อเสีย\n",
    "- **ข้อดี**: เร็ว, ตีความง่าย, ไม่ overfitting\n",
    "- **ข้อเสีย**: ไม่จัดการ non-linear ได้"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# แบ่งข้อมูล\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Linear Regression\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "\n",
    "# ประเมินผล\n",
    "mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
    "r2_lr = r2_score(y_test, y_pred_lr)\n",
    "mae_lr = mean_absolute_error(y_test, y_pred_lr)\n",
    "\n",
    "print(\"Linear Regression Results:\")\n",
    "print(f\"MSE: {mse_lr:.2f}\")\n",
    "print(f\"R²: {r2_lr:.3f}\")\n",
    "print(f\"MAE: {mae_lr:.2f}\")\n",
    "print(f\"Slope: {lr_model.coef_[0]:.2f}\")\n",
    "print(f\"Intercept: {lr_model.intercept_:.2f}\")\n",
    "\n",
    "# แสดงผล\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_test, y_test, alpha=0.6, label='Actual')\n",
    "plt.scatter(X_test, y_pred_lr, alpha=0.6, color='red', label='Predicted')\n",
    "plt.plot(X_test, y_pred_lr, 'r-', alpha=0.8)\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Target')\n",
    "plt.title('Linear Regression Results')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Polynomial Regression\n",
    "\n",
    "### หลักการ\n",
    "- ขยาย Linear Regression ด้วย polynomial features\n",
    "- สมการ: y = ax² + bx + c\n",
    "- จัดการ non-linear relationships ได้\n",
    "- ระวัง overfitting กับ degree สูง"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# สร้างข้อมูล non-linear\n",
    "np.random.seed(42)\n",
    "X_nonlinear = np.sort(np.random.uniform(-2, 2, 100)).reshape(-1, 1)\n",
    "y_nonlinear = 0.5 * X_nonlinear.ravel() ** 2 + 0.3 * X_nonlinear.ravel() + np.random.normal(0, 0.3, 100)\n",
    "\n",
    "X_train_nl, X_test_nl, y_train_nl, y_test_nl = train_test_split(\n",
    "    X_nonlinear, y_nonlinear, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# ทดสอบ polynomial degrees ต่างๆ\n",
    "degrees = [1, 2, 3, 5]\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, degree in enumerate(degrees):\n",
    "    # สร้าง polynomial features\n",
    "    poly_features = PolynomialFeatures(degree=degree)\n",
    "    X_train_poly = poly_features.fit_transform(X_train_nl)\n",
    "    X_test_poly = poly_features.transform(X_test_nl)\n",
    "    \n",
    "    # ฝึก model\n",
    "    poly_model = LinearRegression()\n",
    "    poly_model.fit(X_train_poly, y_train_nl)\n",
    "    \n",
    "    # ทำนาย\n",
    "    y_pred_poly = poly_model.predict(X_test_poly)\n",
    "    r2_poly = r2_score(y_test_nl, y_pred_poly)\n",
    "    \n",
    "    # สร้างเส้นโค้งสำหรับแสดงผล\n",
    "    X_plot = np.linspace(-2, 2, 100).reshape(-1, 1)\n",
    "    X_plot_poly = poly_features.transform(X_plot)\n",
    "    y_plot_poly = poly_model.predict(X_plot_poly)\n",
    "    \n",
    "    # แสดงผล\n",
    "    axes[i].scatter(X_train_nl, y_train_nl, alpha=0.6, label='Train')\n",
    "    axes[i].scatter(X_test_nl, y_test_nl, alpha=0.6, color='red', label='Test')\n",
    "    axes[i].plot(X_plot, y_plot_poly, 'g-', linewidth=2, label='Prediction')\n",
    "    axes[i].set_title(f'Degree {degree}, R² = {r2_poly:.3f}')\n",
    "    axes[i].legend()\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Ridge Regression (L2 Regularization)\n",
    "\n",
    "### หลักการ\n",
    "- เพิ่ม penalty term เพื่อลด overfitting\n",
    "- L2 penalty: λ * Σ(wi²)\n",
    "- ทำให้ coefficients เล็กลง\n",
    "- เหมาะสำหรับ multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# สร้างข้อมูลที่มี multicollinearity\n",
    "np.random.seed(42)\n",
    "n_samples = 100\n",
    "X_multi = np.random.randn(n_samples, 5)\n",
    "# สร้าง correlated features\n",
    "X_multi[:, 1] = X_multi[:, 0] + 0.5 * np.random.randn(n_samples)\n",
    "X_multi[:, 2] = X_multi[:, 0] - 0.3 * np.random.randn(n_samples)\n",
    "\n",
    "# สร้าง target\n",
    "true_coef = np.array([1.5, -2.0, 0.5, 0.8, -1.2])\n",
    "y_multi = X_multi.dot(true_coef) + 0.1 * np.random.randn(n_samples)\n",
    "\n",
    "X_train_multi, X_test_multi, y_train_multi, y_test_multi = train_test_split(\n",
    "    X_multi, y_multi, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# เปรียบเทียบ Linear vs Ridge\n",
    "alphas = [0.1, 1.0, 10.0, 100.0]\n",
    "results = {'Linear': LinearRegression()}\n",
    "\n",
    "for alpha in alphas:\n",
    "    results[f'Ridge (α={alpha})'] = Ridge(alpha=alpha)\n",
    "\n",
    "# ฝึกและประเมิน\n",
    "comparison_results = pd.DataFrame()\n",
    "\n",
    "for name, model in results.items():\n",
    "    model.fit(X_train_multi, y_train_multi)\n",
    "    y_pred = model.predict(X_test_multi)\n",
    "    \n",
    "    metrics = {\n",
    "        'R²': r2_score(y_test_multi, y_pred),\n",
    "        'MSE': mean_squared_error(y_test_multi, y_pred),\n",
    "        'Coef_Sum': np.sum(np.abs(model.coef_))\n",
    "    }\n",
    "    \n",
    "    comparison_results[name] = metrics\n",
    "\n",
    "print(\"Linear vs Ridge Comparison:\")\n",
    "print(comparison_results.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Lasso Regression (L1 Regularization)\n",
    "\n",
    "### หลักการ\n",
    "- L1 penalty: λ * Σ|wi|\n",
    "- ทำ feature selection อัตโนมัติ\n",
    "- บาง coefficients จะเป็น 0\n",
    "- เหมาะสำหรับ sparse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# เปรียบเทียบ Ridge vs Lasso\n",
    "ridge_model = Ridge(alpha=1.0)\n",
    "lasso_model = Lasso(alpha=0.1)\n",
    "\n",
    "ridge_model.fit(X_train_multi, y_train_multi)\n",
    "lasso_model.fit(X_train_multi, y_train_multi)\n",
    "\n",
    "# แสดง coefficients\n",
    "coef_comparison = pd.DataFrame({\n",
    "    'True': true_coef,\n",
    "    'Ridge': ridge_model.coef_,\n",
    "    'Lasso': lasso_model.coef_\n",
    "}, index=[f'Feature {i+1}' for i in range(5)])\n",
    "\n",
    "print(\"Coefficient Comparison:\")\n",
    "print(coef_comparison.round(3))\n",
    "\n",
    "# แสดงผลในรูปกราฟ\n",
    "coef_comparison.plot(kind='bar', figsize=(10, 6))\n",
    "plt.title('Coefficient Comparison: Ridge vs Lasso')\n",
    "plt.ylabel('Coefficient Value')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ประเมินผล\n",
    "ridge_pred = ridge_model.predict(X_test_multi)\n",
    "lasso_pred = lasso_model.predict(X_test_multi)\n",
    "\n",
    "print(f\"\\nRidge R²: {r2_score(y_test_multi, ridge_pred):.3f}\")\n",
    "print(f\"Lasso R²: {r2_score(y_test_multi, lasso_pred):.3f}\")\n",
    "print(f\"\\nNumber of zero coefficients in Lasso: {np.sum(np.abs(lasso_model.coef_) < 1e-5)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Random Forest Regression\n",
    "\n",
    "### หลักการ\n",
    "- Ensemble ของ Decision Trees สำหรับ regression\n",
    "- จัดการ non-linear relationships ได้ดี\n",
    "- ให้ feature importance\n",
    "- ลด overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Regression\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_multi, y_train_multi)\n",
    "rf_pred = rf_model.predict(X_test_multi)\n",
    "\n",
    "print(\"Random Forest Results:\")\n",
    "print(f\"R²: {r2_score(y_test_multi, rf_pred):.3f}\")\n",
    "print(f\"MSE: {mean_squared_error(y_test_multi, rf_pred):.3f}\")\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': [f'Feature {i+1}' for i in range(5)],\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importance:\")\n",
    "print(feature_importance)\n",
    "\n",
    "# แสดงผล\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(data=feature_importance, x='importance', y='feature')\n",
    "plt.title('Feature Importance - Random Forest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Regression Metrics\n",
    "\n",
    "### หลัก Metrics\n",
    "- **MAE**: Mean Absolute Error\n",
    "- **MSE**: Mean Squared Error  \n",
    "- **RMSE**: Root Mean Squared Error\n",
    "- **R²**: Coefficient of Determination\n",
    "\n",
    "### การเลือก Metric\n",
    "- **MAE**: ทนต่อ outliers\n",
    "- **MSE/RMSE**: penalty outliers มากกว่า\n",
    "- **R²**: อธิบายความแปรปรวน"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# เปรียบเทียบ metrics ทั้งหมด\n",
    "models_final = {\n",
    "    'Linear': LinearRegression(),\n",
    "    'Ridge': Ridge(alpha=1.0),\n",
    "    'Lasso': Lasso(alpha=0.1),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "final_results = pd.DataFrame()\n",
    "\n",
    "for name, model in models_final.items():\n",
    "    model.fit(X_train_multi, y_train_multi)\n",
    "    y_pred = model.predict(X_test_multi)\n",
    "    \n",
    "    metrics = {\n",
    "        'MAE': mean_absolute_error(y_test_multi, y_pred),\n",
    "        'MSE': mean_squared_error(y_test_multi, y_pred),\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_test_multi, y_pred)),\n",
    "        'R²': r2_score(y_test_multi, y_pred)\n",
    "    }\n",
    "    \n",
    "    final_results[name] = metrics\n",
    "\n",
    "print(\"Model Comparison - All Metrics:\")\n",
    "print(final_results.round(3))\n",
    "\n",
    "# แสดงผลในรูปกราฟ\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "metrics_to_plot = ['MAE', 'MSE', 'RMSE', 'R²']\n",
    "for i, metric in enumerate(metrics_to_plot):\n",
    "    ax = axes[i//2, i%2]\n",
    "    final_results.loc[metric].plot(kind='bar', ax=ax)\n",
    "    ax.set_title(f'{metric} Comparison')\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## สรุป\n",
    "\n",
    "### Regression Algorithms\n",
    "- **Linear**: เร็ว, ง่าย, linear relationships\n",
    "- **Polynomial**: จัดการ non-linear ได้\n",
    "- **Ridge**: ลด overfitting, multicollinearity\n",
    "- **Lasso**: Feature selection, sparse data\n",
    "- **Random Forest**: ความแม่นยำสูง, non-linear\n",
    "\n",
    "### Metrics\n",
    "- **MAE**: ทนต่อ outliers\n",
    "- **MSE/RMSE**: penalty ขนาดใหญ่\n",
    "- **R²**: อธิบายความแปรปรวน\n",
    "\n",
    "### Next: Regression LAB"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}