{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03g: ML Best Practices และ Conclusion\n",
    "\n",
    "## วัตถุประสงค์การเรียนรู้\n",
    "- เรียนรู้ Best practices ในการทำ ML projects\n",
    "- เข้าใจ Model deployment considerations\n",
    "- รู้จัก Ethical considerations ใน ML\n",
    "- วางแผนการเรียนรู้ต่อไป\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ML Project Best Practices\n",
    "\n",
    "### Data Quality Checklist\n",
    "- ✅ ตรวจสอบ missing values\n",
    "- ✅ หา outliers และ anomalies\n",
    "- ✅ ตรวจสอบ data leakage\n",
    "- ✅ validate business logic\n",
    "\n",
    "### Model Development\n",
    "- ✅ เริ่มต้นด้วย simple baseline\n",
    "- ✅ ใช้ cross-validation\n",
    "- ✅ track experiments\n",
    "- ✅ ป้องกัน overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve, validation_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# สร้างข้อมูลตัวอย่าง\n",
    "X, y = make_classification(n_samples=1000, n_features=10, \n",
    "                          n_informative=5, random_state=42)\n",
    "\n",
    "# 1. Learning Curves - ตรวจสอบ overfitting\n",
    "def plot_learning_curve(model, X, y, title=\"Learning Curve\"):\n",
    "    train_sizes, train_scores, val_scores = learning_curve(\n",
    "        model, X, y, cv=5, n_jobs=-1, \n",
    "        train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    train_mean = train_scores.mean(axis=1)\n",
    "    train_std = train_scores.std(axis=1)\n",
    "    val_mean = val_scores.mean(axis=1)\n",
    "    val_std = val_scores.std(axis=1)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_sizes, train_mean, 'o-', color='blue', label='Training Score')\n",
    "    plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1, color='blue')\n",
    "    \n",
    "    plt.plot(train_sizes, val_mean, 'o-', color='red', label='Cross-Validation Score')\n",
    "    plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, alpha=0.1, color='red')\n",
    "    \n",
    "    plt.xlabel('Training Set Size')\n",
    "    plt.ylabel('Accuracy Score')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "    return train_mean, val_mean\n",
    "\n",
    "# ทดสอบกับ Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "train_scores, val_scores = plot_learning_curve(rf_model, X, y, \"Random Forest Learning Curve\")\n",
    "\n",
    "# วิเคราะห์ผล\n",
    "if train_scores[-1] - val_scores[-1] > 0.05:\n",
    "    print(\"⚠️  Potential Overfitting detected!\")\n",
    "    print(f\"   Training Score: {train_scores[-1]:.3f}\")\n",
    "    print(f\"   Validation Score: {val_scores[-1]:.3f}\")\n",
    "    print(f\"   Gap: {train_scores[-1] - val_scores[-1]:.3f}\")\n",
    "else:\n",
    "    print(\"✅ Model looks good - no significant overfitting\")\n",
    "    print(f\"   Training Score: {train_scores[-1]:.3f}\")\n",
    "    print(f\"   Validation Score: {val_scores[-1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Deployment Considerations\n",
    "\n",
    "### Performance Requirements\n",
    "- **Latency**: เวลาตอบสนอง\n",
    "- **Throughput**: จำนวน requests ต่อวินาที\n",
    "- **Memory Usage**: การใช้หน่วยความจำ\n",
    "- **Model Size**: ขนาดไฟล์ model\n",
    "\n",
    "### Monitoring\n",
    "- **Model Drift**: การเปลี่ยนแปลงของข้อมูล\n",
    "- **Performance Metrics**: ติดตาม accuracy\n",
    "- **Data Quality**: ตรวจสอบข้อมูลใหม่\n",
    "- **Business Metrics**: ผลกระทบต่อธุรกิจ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ตัวอย่าง: Model Monitoring\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class ModelMonitor:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.predictions_log = []\n",
    "        self.performance_log = []\n",
    "        \n",
    "    def predict_with_monitoring(self, X, y_true=None):\n",
    "        \"\"\"\n",
    "        ทำนายพร้อมบันทึก monitoring data\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "        predictions = self.model.predict(X)\n",
    "        prediction_time = time.time() - start_time\n",
    "        \n",
    "        # บันทึก predictions\n",
    "        self.predictions_log.extend(predictions)\n",
    "        \n",
    "        # คำนวณ performance ถ้ามี ground truth\n",
    "        if y_true is not None:\n",
    "            accuracy = accuracy_score(y_true, predictions)\n",
    "            self.performance_log.append({\n",
    "                'timestamp': time.time(),\n",
    "                'accuracy': accuracy,\n",
    "                'prediction_time': prediction_time,\n",
    "                'n_samples': len(X)\n",
    "            })\n",
    "            \n",
    "            print(f\"Prediction completed:\")\n",
    "            print(f\"  Accuracy: {accuracy:.3f}\")\n",
    "            print(f\"  Time: {prediction_time:.4f} seconds\")\n",
    "            print(f\"  Samples: {len(X)}\")\n",
    "            print(f\"  Avg time per sample: {prediction_time/len(X)*1000:.2f} ms\")\n",
    "        \n",
    "        return predictions\n",
    "    \n",
    "    def get_performance_summary(self):\n",
    "        if not self.performance_log:\n",
    "            return \"No performance data available\"\n",
    "            \n",
    "        df = pd.DataFrame(self.performance_log)\n",
    "        return df.describe()\n",
    "\n",
    "# ทดสอบ monitoring\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ฝึก model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# สร้าง monitor\n",
    "monitor = ModelMonitor(rf_model)\n",
    "\n",
    "# ทดสอบ prediction with monitoring\n",
    "predictions = monitor.predict_with_monitoring(X_test, y_test)\n",
    "\n",
    "print(\"\\nPerformance Summary:\")\n",
    "print(monitor.get_performance_summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Ethical Considerations\n",
    "\n",
    "### Bias และ Fairness\n",
    "- **Data Bias**: ข้อมูลมี bias หรือไม่\n",
    "- **Algorithmic Bias**: algorithm เลือกปฏิบัติหรือไม่\n",
    "- **Representation**: กลุ่มต่างๆ ได้รับการเป็นตัวแทนเท่าเทียมหรือไม่\n",
    "- **Impact Assessment**: ผลกระทบต่อกลุ่มต่างๆ\n",
    "\n",
    "### Privacy และ Security\n",
    "- **Data Privacy**: ข้อมูลส่วนบุคคลได้รับการปกป้อง\n",
    "- **Model Security**: ป้องกัน adversarial attacks\n",
    "- **Data Governance**: นโยบายการใช้ข้อมูล\n",
    "- **Compliance**: ปฏิบัติตามกฎหมาย (GDPR, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ตัวอย่าง: Bias Detection\n",
    "def check_prediction_bias(model, X, y, sensitive_feature_idx):\n",
    "    \"\"\"\n",
    "    ตรวจสอบ bias ในการทำนายตาม sensitive feature\n",
    "    \"\"\"\n",
    "    predictions = model.predict(X)\n",
    "    \n",
    "    # แบ่งกลุ่มตาม sensitive feature (เช่น เพศ, อายุ)\n",
    "    sensitive_feature = X[:, sensitive_feature_idx]\n",
    "    threshold = np.median(sensitive_feature)\n",
    "    \n",
    "    group_1 = sensitive_feature <= threshold\n",
    "    group_2 = sensitive_feature > threshold\n",
    "    \n",
    "    # คำนวณ accuracy สำหรับแต่ละกลุ่ม\n",
    "    acc_group_1 = accuracy_score(y[group_1], predictions[group_1])\n",
    "    acc_group_2 = accuracy_score(y[group_2], predictions[group_2])\n",
    "    \n",
    "    # คำนวณ positive rate สำหรับแต่ละกลุ่ม\n",
    "    pos_rate_group_1 = predictions[group_1].mean()\n",
    "    pos_rate_group_2 = predictions[group_2].mean()\n",
    "    \n",
    "    print(\"=== Bias Analysis ===\")\n",
    "    print(f\"Group 1 (feature <= {threshold:.2f}): {group_1.sum()} samples\")\n",
    "    print(f\"  Accuracy: {acc_group_1:.3f}\")\n",
    "    print(f\"  Positive Rate: {pos_rate_group_1:.3f}\")\n",
    "    \n",
    "    print(f\"\\nGroup 2 (feature > {threshold:.2f}): {group_2.sum()} samples\")\n",
    "    print(f\"  Accuracy: {acc_group_2:.3f}\")\n",
    "    print(f\"  Positive Rate: {pos_rate_group_2:.3f}\")\n",
    "    \n",
    "    # คำนวณความแตกต่าง\n",
    "    acc_diff = abs(acc_group_1 - acc_group_2)\n",
    "    rate_diff = abs(pos_rate_group_1 - pos_rate_group_2)\n",
    "    \n",
    "    print(f\"\\nDifferences:\")\n",
    "    print(f\"  Accuracy Difference: {acc_diff:.3f}\")\n",
    "    print(f\"  Positive Rate Difference: {rate_diff:.3f}\")\n",
    "    \n",
    "    # เตือนถ้ามี bias\n",
    "    if acc_diff > 0.05 or rate_diff > 0.1:\n",
    "        print(\"\\n⚠️  Potential bias detected!\")\n",
    "        print(\"   Consider fairness constraints or bias mitigation techniques\")\n",
    "    else:\n",
    "        print(\"\\n✅ No significant bias detected\")\n",
    "    \n",
    "    return acc_diff, rate_diff\n",
    "\n",
    "# ทดสอบ bias detection\n",
    "acc_diff, rate_diff = check_prediction_bias(rf_model, X_test, y_test, sensitive_feature_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ML Best Practices Checklist\n",
    "\n",
    "### Before Starting\n",
    "- [ ] กำหนดปัญหาและเป้าหมายชัดเจน\n",
    "- [ ] เข้าใจ business context\n",
    "- [ ] กำหนด success metrics\n",
    "- [ ] ตรวจสอบ ethical implications\n",
    "\n",
    "### Data Phase\n",
    "- [ ] สำรวจและทำความเข้าใจข้อมูล\n",
    "- [ ] ตรวจสอบ data quality\n",
    "- [ ] จัดการ missing values และ outliers\n",
    "- [ ] แบ่งข้อมูล train/validation/test\n",
    "\n",
    "### Modeling Phase\n",
    "- [ ] เริ่มด้วย simple baseline\n",
    "- [ ] ใช้ cross-validation\n",
    "- [ ] เปรียบเทียบหลาย algorithms\n",
    "- [ ] ทำ hyperparameter tuning\n",
    "- [ ] ตรวจสอบ overfitting\n",
    "\n",
    "### Evaluation Phase\n",
    "- [ ] ประเมินด้วย multiple metrics\n",
    "- [ ] ทดสอบกับ holdout test set\n",
    "- [ ] วิเคราะห์ errors และ edge cases\n",
    "- [ ] ตรวจสอบ bias และ fairness\n",
    "\n",
    "### Deployment Phase\n",
    "- [ ] วางแผน monitoring strategy\n",
    "- [ ] เตรียม rollback plan\n",
    "- [ ] ทดสอบ performance ใน production\n",
    "- [ ] สร้าง documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Next Steps ในการเรียนรู้ ML\n",
    "\n",
    "### พื้นฐานที่ควรเสริม\n",
    "- **Statistics**: Probability, Hypothesis testing\n",
    "- **Linear Algebra**: Matrix operations, Eigenvalues\n",
    "- **Calculus**: Derivatives, Optimization\n",
    "- **Programming**: Python, SQL, Git\n",
    "\n",
    "### Advanced Topics\n",
    "- **Deep Learning**: Neural Networks, CNNs, RNNs\n",
    "- **NLP**: Text processing, Transformers\n",
    "- **Computer Vision**: Image classification, Object detection\n",
    "- **Time Series**: Forecasting, Anomaly detection\n",
    "- **MLOps**: Model deployment, CI/CD for ML\n",
    "\n",
    "### Practical Experience\n",
    "- **Kaggle Competitions**: ฝึกฝนกับปัญหาจริง\n",
    "- **Personal Projects**: สร้าง portfolio\n",
    "- **Open Source**: contribute ใน ML libraries\n",
    "- **Internships**: ประสบการณ์ในบริษัท"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## สรุปการเรียนรู้ทั้งหมด\n",
    "\n",
    "### สิ่งที่เราได้เรียนรู้\n",
    "\n",
    "#### 1. Machine Learning Fundamentals\n",
    "- ความแตกต่างระหว่าง Descriptive และ Predictive Analytics\n",
    "- ประเภทของ ML: Supervised, Unsupervised, Reinforcement\n",
    "- ML Workflow: จากปัญหาสู่การนำไปใช้\n",
    "\n",
    "#### 2. Classification\n",
    "- **Algorithms**: Logistic Regression, Decision Trees, Random Forest\n",
    "- **Metrics**: Accuracy, Precision, Recall, F1-score\n",
    "- **Applications**: Loan default prediction\n",
    "\n",
    "#### 3. Regression\n",
    "- **Algorithms**: Linear, Polynomial, Ridge, Lasso, Random Forest\n",
    "- **Metrics**: MAE, MSE, RMSE, R²\n",
    "- **Applications**: Interest rate prediction\n",
    "\n",
    "#### 4. Best Practices\n",
    "- Data quality และ preprocessing\n",
    "- Model evaluation และ validation\n",
    "- Deployment considerations\n",
    "- Ethical AI และ bias detection\n",
    "\n",
    "### Key Takeaways\n",
    "1. **เริ่มต้นง่ายๆ**: Simple models often work well\n",
    "2. **ข้อมูลคือกุญแจ**: Good data > Complex algorithms\n",
    "3. **Validate เสมอ**: Use cross-validation and holdout sets\n",
    "4. **Think business**: Focus on solving real problems\n",
    "5. **Be ethical**: Consider fairness and bias\n",
    "\n",
    "### การเรียนรู้ต่อไป\n",
    "- ฝึกฝนกับ datasets ใหม่ๆ\n",
    "- เรียนรู้ Deep Learning\n",
    "- ลองทำ end-to-end projects\n",
    "- เข้าร่วมชุมชน ML\n",
    "\n",
    "**ขอให้โชคดีในการเดินทาง Machine Learning! 🚀**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}